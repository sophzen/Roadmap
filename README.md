# Work Roadmap

Technical standards for DL interoperability. This is a temporary repository to organize group work. The long term goal is to open datasets (Physionet/OpenNeuro), so strive for BIDS.
Take a look at [mne-torch](https://github.com/WriessneggerLab/mne-torch).
Please add your experimental data description below:


| Github Handle | N subjects | N trials  | Sample frequency | Trial Length        | Labels                | Description                                                                                                                 |
|---------------|------------|-----------|------------------|---------------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------|
| @abcsds       | 26         | ~900/subj | 500 hz           | 1s (200ms baseline) | 3 (img, sf, toon)     | Visual stimuli: human facial expressions of emotions with two categories: scrambled faces (sf), and cartoonish faces (toon) |
| @melissa05    | 32         | 180/subj  | 500 hz           | 7s (+2s baseline)   | 3 (left, right, both) | ME/MI of hand movement (pressing a ball)                                                                                    |
| @giuliapezzutti | ~25         | ~600/subj | 500 hz | 1.5s (500 baseline) | 6 (original, black/white, blurring, circularblurringext, circularblurringint, edges) | Visual stimuli: human facial expressions of emotions in images manipulated with 6 different image-manipulation techniques
| @sophzen | 30 | ~1900/subj/light condition | 500 hz | 1s | Continous Valance/Arousal(1-9) | Visual stimuli: image in VR during 2 different light conditions. Recording with EEG. Regression to valance/arousal scale.

